diff --git a/train.sh b/train.sh
index 73ec0d4..4cf9f7e 100755
--- a/train.sh
+++ b/train.sh
@@ -10,7 +10,7 @@ helpFunction()
    exit 1
 }
 
-while getopts "d:a:l:n:c:p:u:" opt
+while getopts "d:a:l:n:c:p:u:r:" opt
 do
    case "$opt" in
       d ) d="$OPTARG" ;;
@@ -20,6 +20,7 @@ do
       c ) c="$OPTARG" ;;
       p ) p="$OPTARG" ;;
       u ) u="$OPTARG" ;;
+      r ) r="$OPTARG" ;;
       ? ) helpFunction ;;
    esac
 done
@@ -42,4 +43,4 @@ else
   p=$(get_abs_filename "$p")
 fi
 export CUDA_VISIBLE_DEVICES="$c"
-cd ./train/tasks/semantic;  ./train.py -d "$d"  -ac "$a" -l "$l" -n "$n" -p "$p" -u "$u"
\ No newline at end of file
+cd ./train/tasks/semantic; python3 -m pdb ./train.py -d "$d"  -ac "$a" -l "$l" -n "$n" -p "$p" -u "$u" -dc "$r"
diff --git a/train/common/laserscan.py b/train/common/laserscan.py
index e5c4312..638a178 100644
--- a/train/common/laserscan.py
+++ b/train/common/laserscan.py
@@ -144,6 +144,7 @@ class LaserScan:
 
         # get depth of all points
         depth = np.linalg.norm(self.points, 2, axis=1)
+        depth[depth==0] = 1e-4
 
         # get scan components
         scan_x = self.points[:, 0]
diff --git a/train/common/logger.py b/train/common/logger.py
index bff0f90..3cab4db 100644
--- a/train/common/logger.py
+++ b/train/common/logger.py
@@ -15,17 +15,18 @@ class Logger(object):
 
     def __init__(self, log_dir):
         """Create a summary writer logging to log_dir."""
-        self.writer = tf.summary.FileWriter(log_dir)
+        self.writer = tf.summary.create_file_writer(log_dir)
 
     def scalar_summary(self, tag, value, step):
         """Log a scalar variable."""
-        summary = tf.Summary(
-            value=[tf.Summary.Value(tag=tag, simple_value=value)])
-        self.writer.add_summary(summary, step)
-        self.writer.flush()
+        return
+        with self.writer.as_default():
+            tf.summary.scalar(tag, value, step=step)
+            self.writer.flush()
 
     def image_summary(self, tag, images, step):
         """Log a list of images."""
+        return
 
         img_summaries = []
         for i, img in enumerate(images):
@@ -37,20 +38,21 @@ class Logger(object):
             scipy.misc.toimage(img).save(s, format="png")
 
             # Create an Image object
-            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),
+            img_sum = tf.summary.Image(encoded_image_string=s.getvalue(),
                                        height=img.shape[0],
                                        width=img.shape[1])
             # Create a Summary value
-            img_summaries.append(tf.Summary.Value(
-                tag='%s/%d' % (tag, i), image=img_sum))
+            img_summaries.append(tf.summary.scalar(
+                '%s/%d' % (tag, i), image=img_sum))
 
         # Create and write Summary
-        summary = tf.Summary(value=img_summaries)
+        summary = tf.nummary(value=img_summaries)
         self.writer.add_summary(summary, step)
         self.writer.flush()
 
     def histo_summary(self, tag, values, step, bins=1000):
         """Log a histogram of the tensor of values."""
+        return
 
         # Create a histogram using numpy
         counts, bin_edges = np.histogram(values, bins=bins)
@@ -73,6 +75,6 @@ class Logger(object):
             hist.bucket.append(c)
 
         # Create and write Summary
-        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])
-        self.writer.add_summary(summary, step)
-        self.writer.flush()
+        with self.writer.as_default():
+            tf.summary.scalar(tag, histo=hist, step=step)
+            self.writer.flush()
diff --git a/train/tasks/semantic/config/labels/semantic-kitti.yaml b/train/tasks/semantic/config/labels/semantic-kitti.yaml
index 1d5df93..bacf488 100644
--- a/train/tasks/semantic/config/labels/semantic-kitti.yaml
+++ b/train/tasks/semantic/config/labels/semantic-kitti.yaml
@@ -188,25 +188,7 @@ split: # sequence numbers
   train:
     - 0
     - 1
-    - 2
     - 3
-    - 4
-    - 5
-    - 6
-    - 7
-    - 9
-    - 10
   valid:
-    - 8
+    - 2
   test:
-    - 11
-    - 12
-    - 13
-    - 14
-    - 15
-    - 16
-    - 17
-    - 18
-    - 19
-    - 20
-    - 21
diff --git a/train/tasks/semantic/dataset/rellis/__init__.py b/train/tasks/semantic/dataset/rellis/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/train/tasks/semantic/dataset/rellis/parser.py b/train/tasks/semantic/dataset/rellis/parser.py
new file mode 100644
index 0000000..1c314a9
--- /dev/null
+++ b/train/tasks/semantic/dataset/rellis/parser.py
@@ -0,0 +1,420 @@
+import os
+import numpy as np
+import torch
+from torch.utils.data import Dataset
+from common.laserscan import LaserScan, SemLaserScan
+import torchvision
+
+import torch
+import math
+import random
+from PIL import Image
+try:
+    import accimage
+except ImportError:
+    accimage = None
+import numpy as np
+import numbers
+import types
+from collections.abc import Sequence, Iterable
+import warnings
+
+
+EXTENSIONS_SCAN = ['.bin']
+EXTENSIONS_LABEL = ['.label']
+
+
+def is_scan(filename):
+    return any(filename.endswith(ext) for ext in EXTENSIONS_SCAN)
+
+
+def is_label(filename):
+    return any(filename.endswith(ext) for ext in EXTENSIONS_LABEL)
+
+
+def my_collate(batch):
+    data = [item[0] for item in batch]
+    project_mask = [item[1] for item in batch]
+    proj_labels = [item[2] for item in batch]
+    data = torch.stack(data, dim=0)
+    project_mask = torch.stack(project_mask, dim=0)
+    proj_labels = torch.stack(proj_labels, dim=0)
+
+    to_augment = (proj_labels == 12).nonzero()
+    to_augment_unique_12 = torch.unique(to_augment[:, 0])
+
+    to_augment = (proj_labels == 5).nonzero()
+    to_augment_unique_5 = torch.unique(to_augment[:, 0])
+
+    to_augment = (proj_labels == 8).nonzero()
+    to_augment_unique_8 = torch.unique(to_augment[:, 0])
+
+    to_augment_unique = torch.cat(
+        (to_augment_unique_5, to_augment_unique_8, to_augment_unique_12), dim=0)
+    to_augment_unique = torch.unique(to_augment_unique)
+
+    for k in to_augment_unique:
+        data = torch.cat(
+            (data, torch.flip(data[k.item()], [2]).unsqueeze(0)), dim=0)
+        proj_labels = torch.cat((proj_labels, torch.flip(
+            proj_labels[k.item()], [1]).unsqueeze(0)), dim=0)
+        project_mask = torch.cat((project_mask, torch.flip(
+            project_mask[k.item()], [1]).unsqueeze(0)), dim=0)
+
+    return data, project_mask, proj_labels
+
+
+class Rellis(Dataset):
+
+    def __init__(self, root,    # directory where data is
+                 sequences,     # sequences for this data (e.g. [1,3,4,6])
+                 labels,        # label dict: (e.g 10: "car")
+                 color_map,     # colors dict bgr (e.g 10: [255, 0, 0])
+                 learning_map,  # classes to learn (0 to N-1 for xentropy)
+                 learning_map_inv,    # inverse of previous (recover labels)
+                 sensor,              # sensor to parse scans from
+                 max_points=150000,   # max number of points present in dataset
+                 gt=True,
+                 transform=False):            # send ground truth?
+        # save deats
+        self.root = root
+        self.sequences = sequences
+        self.labels = labels
+        self.color_map = color_map
+        self.learning_map = learning_map
+        self.learning_map_inv = learning_map_inv
+        self.sensor = sensor
+        self.sensor_img_H = sensor["img_prop"]["height"]
+        self.sensor_img_W = sensor["img_prop"]["width"]
+        self.sensor_img_means = torch.tensor(sensor["img_means"],
+                                             dtype=torch.float)
+        self.sensor_img_stds = torch.tensor(sensor["img_stds"],
+                                            dtype=torch.float)
+        self.sensor_fov_up = sensor["fov_up"]
+        self.sensor_fov_down = sensor["fov_down"]
+        self.max_points = max_points
+        self.gt = gt
+        self.transform = transform
+
+        # get number of classes (can't be len(self.learning_map) because there
+        # are multiple repeated entries, so the number that matters is how many
+        # there are for the xentropy)
+        self.nclasses = len(self.learning_map_inv)
+
+        # sanity checks
+
+        # make sure directory exists
+        if os.path.isdir(self.root):
+            print("Sequences folder exists! Using sequences from %s" % self.root)
+        else:
+            raise ValueError("Sequences folder doesn't exist! Exiting...%s" % self.root)
+
+        # make sure labels is a dict
+        assert(isinstance(self.labels, dict))
+
+        # make sure color_map is a dict
+        assert(isinstance(self.color_map, dict))
+
+        # make sure learning_map is a dict
+        assert(isinstance(self.learning_map, dict))
+
+        # make sure sequences is a list
+        assert(isinstance(self.sequences, str))
+
+        # placeholder for filenames
+
+        lst_path = os.path.join(self.root,self.sequences)
+        self.file_list = [line.strip().split() for line in open(lst_path)]
+        self.scan_files = []
+        self.label_files = []
+
+        # fill in with names, checking that all sequences are complete
+        for item in self.file_list:
+            scan_path, label_path = item
+            scan_path = os.path.join(self.root, scan_path)
+            label_path = os.path.join(self.root, label_path)
+            self.scan_files.append(scan_path)
+            self.label_files.append(label_path)
+
+        # sort for correspondance
+        self.scan_files.sort()
+        self.label_files.sort()
+
+        print("Using {} scans from sequences {}".format(len(self.scan_files),self.sequences))
+
+    def __getitem__(self, index):
+        # get item in tensor shape
+        scan_file = self.scan_files[index]
+        if self.gt:
+            label_file = self.label_files[index]
+
+        # open a semantic laserscan
+        DA = False
+        flip_sign = False
+        rot = False
+        drop_points = False
+        if self.transform:
+            if random.random() > 0.5:
+                if random.random() > 0.5:
+                    DA = True
+                if random.random() > 0.5:
+                    flip_sign = True
+                if random.random() > 0.5:
+                    rot = True
+                drop_points = random.uniform(0, 0.5)
+
+        if self.gt:
+            scan = SemLaserScan(self.color_map,
+                                project=True,
+                                H=self.sensor_img_H,
+                                W=self.sensor_img_W,
+                                fov_up=self.sensor_fov_up,
+                                fov_down=self.sensor_fov_down,
+                                DA=DA,
+                                flip_sign=flip_sign,
+                                drop_points=drop_points)
+        else:
+            scan = LaserScan(project=True,
+                             H=self.sensor_img_H,
+                             W=self.sensor_img_W,
+                             fov_up=self.sensor_fov_up,
+                             fov_down=self.sensor_fov_down,
+                             DA=DA,
+                             rot=rot,
+                             flip_sign=flip_sign,
+                             drop_points=drop_points)
+
+        # open and obtain scan
+        scan.open_scan(scan_file)
+        if self.gt:
+            scan.open_label(label_file)
+            # map unused classes to used classes (also for projection)
+            scan.sem_label = self.map(scan.sem_label, self.learning_map)
+            scan.proj_sem_label = self.map(
+                scan.proj_sem_label, self.learning_map)
+
+        # make a tensor of the uncompressed data (with the max num points)
+        unproj_n_points = scan.points.shape[0]
+        unproj_xyz = torch.full((self.max_points, 3), -1.0, dtype=torch.float)
+        unproj_xyz[:unproj_n_points] = torch.from_numpy(scan.points)
+        unproj_range = torch.full([self.max_points], -1.0, dtype=torch.float)
+        unproj_range[:unproj_n_points] = torch.from_numpy(scan.unproj_range)
+        unproj_remissions = torch.full(
+            [self.max_points], -1.0, dtype=torch.float)
+        unproj_remissions[:unproj_n_points] = torch.from_numpy(scan.remissions)
+        if self.gt:
+            unproj_labels = torch.full(
+                [self.max_points], -1.0, dtype=torch.int32)
+            unproj_labels[:unproj_n_points] = torch.from_numpy(scan.sem_label)
+        else:
+            unproj_labels = []
+
+        # get points and labels
+        proj_range = torch.from_numpy(scan.proj_range).clone()
+        proj_xyz = torch.from_numpy(scan.proj_xyz).clone()
+        proj_remission = torch.from_numpy(scan.proj_remission).clone()
+        proj_mask = torch.from_numpy(scan.proj_mask)
+        if self.gt:
+            proj_labels = torch.from_numpy(scan.proj_sem_label).clone()
+            proj_labels = proj_labels * proj_mask
+        else:
+            proj_labels = []
+        proj_x = torch.full([self.max_points], -1, dtype=torch.long)
+        proj_x[:unproj_n_points] = torch.from_numpy(scan.proj_x)
+        proj_y = torch.full([self.max_points], -1, dtype=torch.long)
+        proj_y[:unproj_n_points] = torch.from_numpy(scan.proj_y)
+        proj = torch.cat([proj_range.unsqueeze(0).clone(),
+                          proj_xyz.clone().permute(2, 0, 1),
+                          proj_remission.unsqueeze(0).clone()])
+        proj = (proj - self.sensor_img_means[:, None, None]
+                ) / self.sensor_img_stds[:, None, None]
+        proj = proj * proj_mask.float()
+
+        # get name and sequence
+        path_norm = os.path.normpath(scan_file)
+        path_split = path_norm.split(os.sep)
+        path_seq = path_split[-3]
+        path_name = path_split[-1].replace(".bin", ".label")
+
+        # return
+        return proj, proj_mask, proj_labels, unproj_labels, path_seq, path_name, proj_x, proj_y, proj_range, unproj_range, proj_xyz, unproj_xyz, proj_remission, unproj_remissions, unproj_n_points
+
+    def __len__(self):
+        return len(self.scan_files)
+
+    @staticmethod
+    def map(label, mapdict):
+        # put label from original values to xentropy
+        # or vice-versa, depending on dictionary values
+        # make learning map a lookup table
+        maxkey = 0
+        for key, data in mapdict.items():
+            if isinstance(data, list):
+                nel = len(data)
+            else:
+                nel = 1
+            if key > maxkey:
+                maxkey = key
+        # +100 hack making lut bigger just in case there are unknown labels
+        if nel > 1:
+            lut = np.zeros((maxkey + 100, nel), dtype=np.int32)
+        else:
+            lut = np.zeros((maxkey + 100), dtype=np.int32)
+        for key, data in mapdict.items():
+            try:
+                lut[key] = data
+            except IndexError:
+                print("Wrong key ", key)
+        # do the mapping
+        return lut[label]
+
+
+class Parser():
+    # standard conv, BN, relu
+    def __init__(self,
+                 root,              # directory for data
+                 train_sequences,   # sequences to train
+                 valid_sequences,   # sequences to validate.
+                 test_sequences,    # sequences to test (if none, don't get)
+                 labels,            # labels in data
+                 color_map,         # color for each label
+                 learning_map,      # mapping for training labels
+                 learning_map_inv,  # recover labels from xentropy
+                 sensor,            # sensor to use
+                 max_points,        # max points in each scan in entire dataset
+                 batch_size,        # batch size for train and val
+                 workers,           # threads to load data
+                 gt=True,           # get gt?
+                 shuffle_train=True):  # shuffle training set?
+        super(Parser, self).__init__()
+
+        # if I am training, get the dataset
+        self.root = root
+        self.train_sequences = train_sequences
+        self.valid_sequences = valid_sequences
+        self.test_sequences = test_sequences
+        self.labels = labels
+        self.color_map = color_map
+        self.learning_map = learning_map
+        self.learning_map_inv = learning_map_inv
+        self.sensor = sensor
+        self.max_points = max_points
+        self.batch_size = batch_size
+        self.workers = workers
+        self.gt = gt
+        self.shuffle_train = shuffle_train
+
+        # number of classes that matters is the one for xentropy
+        self.nclasses = len(self.learning_map_inv)
+
+        # Data loading code
+        self.train_dataset = Rellis(root=self.root,
+                                    sequences=self.train_sequences,
+                                    labels=self.labels,
+                                    color_map=self.color_map,
+                                    learning_map=self.learning_map,
+                                    learning_map_inv=self.learning_map_inv,
+                                    sensor=self.sensor,
+                                    max_points=max_points,
+                                    gt=self.gt)
+                                   #transform=True,
+
+        self.trainloader = torch.utils.data.DataLoader(self.train_dataset,
+                                                       batch_size=self.batch_size,
+                                                       shuffle=self.shuffle_train,
+                                                       num_workers=self.workers,
+                                                       drop_last=True)
+        
+        assert len(self.trainloader) > 0, f"len(self.trainloader):{len(self.trainloader)}"
+        self.trainiter = iter(self.trainloader)
+
+        self.valid_dataset = Rellis(root=self.root,
+                                    sequences=self.valid_sequences,
+                                    labels=self.labels,
+                                    color_map=self.color_map,
+                                    learning_map=self.learning_map,
+                                    learning_map_inv=self.learning_map_inv,
+                                    sensor=self.sensor,
+                                    max_points=max_points,
+                                    gt=self.gt)
+
+        self.validloader = torch.utils.data.DataLoader(self.valid_dataset,
+                                                       batch_size=self.batch_size,
+                                                       shuffle=False,
+                                                       num_workers=self.workers,
+                                                       drop_last=True)
+        assert len(self.validloader) > 0
+        self.validiter = iter(self.validloader)
+
+        if self.test_sequences:
+            self.test_dataset = Rellis(root=self.root,
+                                       sequences=self.test_sequences,
+                                       labels=self.labels,
+                                       color_map=self.color_map,
+                                       learning_map=self.learning_map,
+                                       learning_map_inv=self.learning_map_inv,
+                                       sensor=self.sensor,
+                                       max_points=max_points,
+                                       gt=False)
+
+            self.testloader = torch.utils.data.DataLoader(self.test_dataset,
+                                                          batch_size=self.batch_size,
+                                                          shuffle=False,
+                                                          num_workers=self.workers,
+                                                          drop_last=True)
+            assert len(self.testloader) > 0
+            self.testiter = iter(self.testloader)
+
+    def get_train_batch(self):
+        scans = self.trainiter.next()
+        return scans
+
+    def get_train_set(self):
+        return self.trainloader
+
+    def get_valid_batch(self):
+        scans = self.validiter.next()
+        return scans
+
+    def get_valid_set(self):
+        return self.validloader
+
+    def get_test_batch(self):
+        scans = self.testiter.next()
+        return scans
+
+    def get_test_set(self):
+        return self.testloader
+
+    def get_train_size(self):
+        return len(self.trainloader)
+
+    def get_valid_size(self):
+        return len(self.validloader)
+
+    def get_test_size(self):
+        return len(self.testloader)
+
+    def get_n_classes(self):
+        return self.nclasses
+
+    def get_original_class_string(self, idx):
+        return self.labels[idx]
+
+    def get_xentropy_class_string(self, idx):
+        return self.labels[self.learning_map_inv[idx]]
+
+    def to_original(self, label):
+        # put label in original values
+        return Rellis.map(label, self.learning_map_inv)
+
+    def to_xentropy(self, label):
+        # put label in xentropy values
+        return Rellis.map(label, self.learning_map)
+
+    def to_color(self, label):
+        # put label in original values
+        label = Rellis.map(label, self.learning_map_inv)
+        # put label in color
+        return Rellis.map(label, self.color_map)
+
